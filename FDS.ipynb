{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH =  os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i code/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prompts user for FDS and fds2ascii executable paths & email to send notifcation\n",
    "#fds_bin = input('File path to FDS executable: ')\n",
    "#fds2ascii = input('File path to fds2ascii utility in FDS: ')\n",
    "#fds_bin = '/home1/02410/lvalera/fds/Build/impi_intel_linux_64/fds_impi_intel_linux_64'          # Stampede2/FRONTERA\n",
    "fds_bin ='/home1/02410/lvalera/Temporal/fds/Build/impi_intel_linux_64/fds_impi_intel_linux_64'\n",
    "fds2ascii = '/home1/02410/lvalera/FDS/FDS6/bin/fds2ascii'               # Stampede2/FRONTERA\n",
    "\n",
    "#fds_bin = '/home/leobardovalera/FDS/FDS6/bin/fds'             # Local\n",
    "#fds2ascii = '/home/leobardovalera/FDS/FDS6/bin/fds2ascii'     # Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Initial Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in elevation file to extract region information\n",
    "name_of_file = f'{PATH}/data/Elevations_Files/gatlinburg_res_1x1.elv'\n",
    "Mst_original = pd.read_csv(name_of_file )\n",
    "Image_name   = f\"{PATH}/data/Regions_Images/Gatlinburg_texted.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Coordinates\n",
    "North = 1000\n",
    "South = 0\n",
    "East  = 1000\n",
    "West  = 0\n",
    "# Coordinates of the Region's Border \n",
    "Min_x = 500      \n",
    "Max_x = 700\n",
    "\n",
    "Min_y = 200\n",
    "Max_y = 400\n",
    "\n",
    "Mst   = Mst_original.copy()\n",
    "Mst = Mst[(Mst.x >= Min_x) \n",
    "        & (Mst.x <= Max_x) \n",
    "        & (Mst.y >= Min_y) \n",
    "        & (Mst.y <= Max_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the Resolution of the Meshes and the obstacles (in Meters)\n",
    "R = 2                                   # Resolution of Cells\n",
    "Mst = Mst[(Mst.x%R==0) & (Mst.y%R==0)]  # Filters data \n",
    "Ro = 2    # Resolution of Obstacles\n",
    "\n",
    "# Radius of the fire from the center\n",
    "fire_radius   = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines range of elevation\n",
    "Min_z = 380\n",
    "Max_z = 620\n",
    "Regiones = [Min_x,Max_x,Min_y,Max_y,Min_z,Max_z]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Input FDS File Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for regions that we are simulating\n",
    "num_region = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set time interval\n",
    "T_begin    = 0.0\n",
    "DTT        = 10.0\n",
    "T_end      = T_begin + DTT\n",
    "DT         = 0.1\n",
    "\n",
    "# Set Number of meshes in x, y, z directions\n",
    "Nmx        = 2     \n",
    "Nmy        = 2    \n",
    "Nmz        = 4\n",
    "\n",
    "PC         = 1         # Predictor-Corrector Status Flag\n",
    "Location   = [608,260] # Initial Location of the fire\n",
    "Child      = f\"Region{num_region}\" # Start of Sequential Domain Decomposition\n",
    "#Child      = f\"Region\"\n",
    "\n",
    "HRRPUA     = 3500      # Heat Release Rate (HRR)\n",
    "rampa_time = 15       # Time that the fire ramp lasts\n",
    "\n",
    "UVW_Timer  = 0\n",
    "DT_UVW_Timer = DTT\n",
    "UVW_Timer  =  UVW_Timer + DT_UVW_Timer      # Time\n",
    "\n",
    "\n",
    "# File name conventions\n",
    "foldername = f'Gatlinburg2'\n",
    "filename   = f'{Child}.fds'\n",
    "\n",
    "# Heat Release Rate (HRR) Minimum\n",
    "#hrr_threshold = Ro*Ro*Ro\n",
    "\n",
    "# Defining the dataframe with the HRR information\n",
    "Hrr = Mst[(Mst['x'] <= Location[0]+2*Ro) & (Mst['x'] >= Location[0]-2*Ro) & (Mst['y'] <= Location[1]+2*Ro) & (Mst['y'] >= Location[1]-2*Ro)]\n",
    "Hrr = Hrr[[Hrr.columns[0],Hrr.columns[1]]]\n",
    "Hrr['hrr'] = HRRPUA\n",
    "\n",
    "if not path.exists(f\"{PATH}/simulations/{foldername}\"):\n",
    "    os.mkdir(f\"{PATH}/simulations/{foldername}\")\n",
    "\n",
    "if not path.exists(f\"{PATH}/simulations/{foldername}/{Child}\"):\n",
    "    os.mkdir(f\"{PATH}/simulations/{foldername}/{Child}\")\n",
    "\n",
    "Hrr.to_csv(f'{PATH}/simulations/{foldername}/{Child}/Hrr_{Child}.csv', index=False)\n",
    "# Function to write input FDS file with parameter specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "write_fds_file(T_begin, T_end, DT, PC, Nmx, Nmy, Nmz, Hrr, Child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Sets Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDS_FOLDER = f\"simulations/{foldername}/{Child}\" # Location of input FDS file\n",
    "\n",
    "os.chdir(f'{PATH}/{FDS_FOLDER}')      # Changes directory to run the input FDS file location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Runs FDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User decides to run as a job on a job scheduler or directly through mpiexec command\n",
    "#job_type = input(\"Are you running with a job scheduler? \\nIf so, is it LSF or Slurm?\\nIf not, you do not have to specify. \")\n",
    "job_type =''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets variables to use in job scripts/commands\n",
    "num_nodes = 1             # Number of compute nodes to run job on\n",
    "max_time = '3:00'         # Max time needed to run job (d-hh:mm:ss)\n",
    "number_of_process =Nmx*Nmy*Nmz      # Number of processes(cores) needed to run the created meshes\n",
    "omp_threads = 4           # Sets OpenMP Threads per process\n",
    "jobName = f'FDS_{Child}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options: LSF, Slurm, or direct command (mpiexec)\n",
    "if job_type==\"LSF\" or job_type==\"Lsf\" or job_type=='lsf':\n",
    "    USER = os.getlogin()\n",
    "    create_job_script_lsf(Child, num_nodes, max_time, omp_threads)    # Creates LSF job submission script\n",
    "    os.system(f'bsub < job_{Child}.bsub') # Submits job script to the LSF job scheduler\n",
    "    \n",
    "    job_id = Get_job_id(['bjobs', '-u', USER])\n",
    "    jobs = [job_id]\n",
    "    wait_on_lsf()\n",
    "    \n",
    "elif job_type==\"SLURM\" or job_type==\"Slurm\" or job_type==\"slurm\":\n",
    "    USER = os.getlogin()\n",
    "    \n",
    "#     partition = 'skx-normal' # Can be changed to another other partition used on TACC's Stampede2\n",
    "    \n",
    "    create_job_script_slurm(Child, num_nodes, max_time, omp_threads)  # Creates Slurm job submission script\n",
    "    os.system(f'sbatch job_{Child}.sh')   # Submits job script to the Slurm job Scheduler\n",
    "    \n",
    "    job_id - Get_job_id(['squeue', '-u', USER])\n",
    "    jobs = [job_id]\n",
    "    wait_on_slurm()\n",
    "    \n",
    "else: \n",
    "    os.environ['OMP_NUM_THREADS'] = f'{omp_threads}'                  # Sets OpenMP Threads to 4\n",
    "    os.system(f\"mpiexec -n {number_of_process} {fds_bin} {filename}\") # Runs FDS using 'mpiexec' command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Checkpoint Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Parses plot3d files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Run_Region = False\n",
    "\n",
    "UVW_Timer  =  UVW_Timer + DT_UVW_Timer      # Time\n",
    "\n",
    "while(Run_Region):\n",
    "    quantity     = f\"hrrpuv\"\n",
    "    first        = 1\n",
    "    step         = 1\n",
    "    meshes       = Nmx*Nmy*Nmz\n",
    "    t_start      = T_end\n",
    "    t_end        = T_end\n",
    "    file         = \"fds2ascii.txt\"\n",
    "    \n",
    "    if (num_region>=1):\n",
    "        hrrpuv = reading_slide(f\"{Child}_cat\",quantity,first,step,meshes,'./',t_start,t_end,file)\n",
    "    else:\n",
    "        hrrpuv = reading_slide(f\"{Child}\",quantity,first,step,meshes,'./',t_start,t_end,file)\n",
    "    # Removing the repeated values\n",
    "    # The values are repeated on the border of the meshes, so we need to remove the duplicated ones \n",
    "    hrrpuv = hrrpuv.drop_duplicates(subset = ['x', 'y','z'],keep = 'first').reset_index(drop = True)\n",
    "    \n",
    "    # Dropping zero values\n",
    "    hrrpuv = hrrpuv[hrrpuv['hrr']>0].reset_index(drop = True) \n",
    "    hrrpuv['hrr'].to_csv(f\"hrrpuv_{Child}_ini.csv\",index=False)\n",
    "    # Taking into account the radiation fraction\n",
    "    #file1 = open(f'{Child}_hrr.csv', 'r') \n",
    "    #Lines = file1.readlines() \n",
    "    #total_hrr_region1 = Lines[-1].split(',')[1]\n",
    "    #radiac_fact =  float(total_hrr_region1)/(Ro*Ro*Ro*hrrpuv['hrr'].sum())\n",
    "    #hrrpuv['hrr'] = radiac_fact*hrrpuv['hrr'] \n",
    "    \n",
    "    # Creating the Input data for the next region\n",
    "    init_file = f'{Child}.ini'\n",
    "    hrrpuv = setting_initialization(hrrpuv,Ro,init_file)\n",
    "    \n",
    "    minimo_x = hrrpuv['x'].min()\n",
    "    maximo_x = hrrpuv['x'].max()\n",
    "  \n",
    "    minimo_y = hrrpuv['y'].min()\n",
    "    maximo_y = hrrpuv['y'].max()\n",
    "\n",
    "    # Defining the center of the location of the fire\n",
    "\n",
    "    if (math.isnan(minimo_x) or math.isnan(maximo_x) or math.isnan(minimo_y) or math.isnan(maximo_y)):\n",
    "        break\n",
    "    center_x = math.floor((minimo_x+maximo_x)/2)\n",
    "    center_y = math.floor((minimo_y+maximo_y)/2)\n",
    "    \n",
    "    center_x = center_x - (center_x%Ro)\n",
    "    center_y = center_y - (center_y%Ro)\n",
    "    \n",
    "    if ((center_x < West)  or (center_x > East) or (center_y < South) or (center_y > North)):\n",
    "        break\n",
    "    \n",
    "    # Update Region Number to next one, if needed\n",
    "    num_region = num_region + 1\n",
    "    \n",
    "    print(minimo_x)\n",
    "    print(maximo_x)\n",
    "    print(minimo_y)\n",
    "    print(maximo_y)\n",
    "    Min_x = int(input('Input lower bound of x variable: '))\n",
    "    Max_x = int(input('Input upper bound of x variable: '))\n",
    "    Min_y = int(input('Input lower bound of y variable: '))\n",
    "    Max_y = int(input('Input upper bound of y variable: '))\n",
    "    DTT = float(input('How long would you like to simulate in this region: '))\n",
    "    \n",
    "    Mst   = Mst_original.copy()\n",
    "\n",
    "    Mst = Mst[(Mst.x >= Min_x) \n",
    "        & (Mst.x <= Max_x) \n",
    "        & (Mst.y >= Min_y) \n",
    "        & (Mst.y <= Max_y)]\n",
    "    # Range of elevation\n",
    "    # Defines range of elevation\n",
    "    Min_z = 380\n",
    "    Max_z = 620\n",
    "\n",
    "    Regiones.append([Min_x,Max_x,Min_y,Max_y,Min_z,Max_z])\n",
    "    if(Hrr['hrr'].sum()==0):\n",
    "        break\n",
    "    \n",
    "    if (Hrr.shape[0] < 1):\n",
    "        break\n",
    "    # Repeat Steps 1.2 - 3 (Loop)\n",
    "\n",
    "    # Defines input variables for the next region (with respect to the previous FDS run)\n",
    "    T_begin = T_end\n",
    "    T_end   = T_begin+DTT\n",
    "    Child_pr= Child\n",
    "    Child   = f\"Region{num_region}\"\n",
    "    filename   = f'{Child}.fds'\n",
    "    \n",
    "    if not path.exists(f\"{PATH}/simulations/{foldername}/{Child}\"):\n",
    "        os.mkdir(f\"{PATH}/simulations/{foldername}/{Child}\")\n",
    "    \n",
    "    FDS_FOLDER = f\"simulations/{foldername}/{Child}\" # Location of input FDS fil\n",
    "    os.chdir(f'{PATH}/{FDS_FOLDER}')      # Changes directory to run the input FDS file location\n",
    "    \n",
    "    restart_fds_file(T_begin, T_end, DT, PC, Nmx, Nmy, Nmz,Child)\n",
    "    \n",
    "    # Clear the list of jobids\n",
    "    if 'jobs' in locals():\n",
    "        jobs.clear()\n",
    "\n",
    "    # Options: LSF, Slurm, or direct command (mpiexec)\n",
    "    if job_type==\"LSF\" or job_type==\"Lsf\" or job_type=='lsf':\n",
    "        create_job_script_lsf(Child, num_nodes, max_time, omp_threads)    # Creates LSF job submission script\n",
    "        os.system(f'bsub < job_{Child}.bsub') # Submits job script to the LSF job scheduler\n",
    "\n",
    "        job_id = Get_job_id(['bjobs', '-u', USER])\n",
    "        #job_id = input(\"Enter Job ID just started: \") # Gets the job id & waits for it to finish to run the rest of the notebook\n",
    "        jobs = [job_id]\n",
    "        wait_on_lsf()\n",
    "    elif job_type==\"SLURM\" or job_type==\"Slurm\" or job_type==\"slurm\":\n",
    "        create_job_script_slurm(Child, num_nodes, max_time, omp_threads)  # Creates Slurm job submission script\n",
    "        os.system(f'sbatch job_{Child}.sh')   # Submits job script to the Slurm job Scheduler\n",
    "\n",
    "        job_id = input(\"Enter Job ID just started: \") # Gets the job id & waits for it to finish to run the rest of the notebook\n",
    "        jobs = [job_id]\n",
    "        wait_on_slurm()\n",
    "    else: \n",
    "        os.environ['OMP_NUM_THREADS'] = f'{omp_threads}'                  # Sets OpenMP Threads to 4\n",
    "        os.system(f\"mpiexec -n {number_of_process} {fds_bin} {filename}\") # Runs FDS using 'mpiexec' command\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regiones.to_csv('Regiones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
