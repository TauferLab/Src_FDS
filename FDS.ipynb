{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH =  os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i code/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prompts user for FDS and fds2ascii executable paths & email to send notifcation\n",
    "#fds_bin = input('File path to FDS executable: ')\n",
    "#fds2ascii = input('File path to fds2ascii utility in FDS: ')\n",
    "fds_bin = '/home1/02410/lvalera/FDS/FDS6.7.5/bin/fds'          # Stampede2\n",
    "fds2ascii = '/home1/02410/lvalera/FDS/FDS6.7.5/bin/fds2ascii'  # Stampede2\n",
    "\n",
    "#fds_bin = '/home/leobardovalera/FDS/FDS6/bin/fds'             # Local\n",
    "#fds2ascii = '/home/leobardovalera/FDS/FDS6/bin/fds2ascii'     # Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Initial Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in elevation file to extract region information\n",
    "name_of_file = 'Data/chimmey_tops_dem_1m_utm17n.csv'\n",
    "Mst_original = read_elevation(name_of_file)\n",
    "Image_name   = 'Image/Chimney_tops_aerial_Big.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Coordinates\n",
    "North = 1000\n",
    "South = 0\n",
    "East  = 1000\n",
    "West  = 0\n",
    "# Coordinates of the Region's Border \n",
    "Min_x = 400      \n",
    "Max_x = 600\n",
    "\n",
    "Min_y = 0\n",
    "Max_y = 200\n",
    "\n",
    "Mst   = Mst_original.copy()\n",
    "Mst['Elevation']   = Mst['Elevation']-Mst['Elevation'].min()\n",
    "Mst = Mst[(Mst.x >= Min_x) \n",
    "        & (Mst.x <= Max_x) \n",
    "        & (Mst.y >= Min_y) \n",
    "        & (Mst.y <= Max_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the Resolution of the Meshes and the obstacles (in Meters)\n",
    "R = 2                                   # Resolution of Cells\n",
    "Mst = Mst[(Mst.x%R==0) & (Mst.y%R==0)]  # Filters data \n",
    "Ro = 2    # Resolution of Obstacles\n",
    "\n",
    "Mst['Elevation'] = Mst['Elevation']-Mst['Elevation']%Ro\n",
    "\n",
    "# Radius of the fire from the center\n",
    "fire_radius   = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines range of elevation\n",
    "Min_z = math.floor(Mst['Elevation'].min())\n",
    "Min_z = Min_z-(Min_z%(2*R))\n",
    "Max_z = math.ceil(Mst['Elevation'].max())\n",
    "Max_z = Max_z + (2*R-Max_z%(2*R))\n",
    "Medio_z =  (Min_z + Max_z)/2\n",
    "Min_z   = Medio_z-fire_radius\n",
    "Max_z   = Medio_z+fire_radius\n",
    "#Min_z    = 200\n",
    "#Max_z    = 500\n",
    "Regiones = [[Min_x,Max_x,Min_y,Max_y,Min_z,Max_z]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Input FDS File Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for regions that we are simulating\n",
    "num_region = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set time interval\n",
    "T_begin    = 0.0\n",
    "DTT        = 80.0\n",
    "T_end      = T_begin + DTT\n",
    "DT         = 0.1\n",
    "\n",
    "# Set Number of meshes in x, y, z directions\n",
    "Nmx        = 2     \n",
    "Nmy        = 2     \n",
    "Nmz        = 2\n",
    "\n",
    "PC         = 1         # Predictor-Corrector Status Flag\n",
    "Location   = [500,100] # Initial Location of the fire\n",
    "Child      = f\"Region{num_region}\" # Start of Sequential Domain Decomposition\n",
    "HRRPUA     = 1500      # Heat Release Rate (HRR)\n",
    "rampa_time = 8       # Time that the fire ramp lasts\n",
    "\n",
    "UVW_Timer  = 0\n",
    "DT_UVW_Timer = 60\n",
    "UVW_Timer  =  UVW_Timer + DT_UVW_Timer      # Time\n",
    "\n",
    "\n",
    "# File name conventions\n",
    "foldername = f'chimney'\n",
    "filename   = f'{Child}.fds'\n",
    "\n",
    "# Heat Release Rate (HRR) Minimum\n",
    "hrr_threshold = Ro*Ro*Ro\n",
    "\n",
    "# Defining the dataframe with the HRR information\n",
    "Hrr = Mst[(Mst['x'] < Location[0]+Ro+1) & (Mst['x'] > Location[0]-Ro-1) & (Mst['y'] < Location[1]+Ro+1) & (Mst['y'] > Location[1]-Ro-1)]\n",
    "Hrr = Hrr[[Hrr.columns[0],Hrr.columns[1]]]\n",
    "Hrr['hrr'] = HRRPUA\n",
    "Hrr.to_csv(f'{PATH}/FDSFiles/{foldername}/Hrr_{Child}.csv', index=False)\n",
    "# Function to write input FDS file with parameter specified above\n",
    "write_fds_file(T_begin, T_end, DT, PC, Nmx, Nmy, Nmz, Hrr, Child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Sets Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDS_FOLDER = f\"FDSFiles/{foldername}\" # Location of input FDS file\n",
    "\n",
    "os.chdir(f'{PATH}/{FDS_FOLDER}')      # Changes directory to run the input FDS file location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Runs FDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User decides to run as a job on a job scheduler or directly through mpiexec command\n",
    "#job_type = input(\"Are you running with a job scheduler? \\nIf so, is it LSF or Slurm?\\nIf not, you do not have to specify. \")\n",
    "job_type =''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets variables to use in job scripts/commands\n",
    "num_nodes = 1             # Number of compute nodes to run job on\n",
    "max_time = '3:00'         # Max time needed to run job (d-hh:mm:ss)\n",
    "number_of_process = 8     # Number of processes(cores) needed to run the created meshes\n",
    "omp_threads = 4           # Sets OpenMP Threads per process\n",
    "jobName = f'FDS_{Child}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options: LSF, Slurm, or direct command (mpiexec)\n",
    "if job_type==\"LSF\" or job_type==\"Lsf\" or job_type=='lsf':\n",
    "    USER = os.getlogin()\n",
    "    create_job_script_lsf(Child, num_nodes, max_time, omp_threads)    # Creates LSF job submission script\n",
    "    os.system(f'bsub < job_{Child}.bsub') # Submits job script to the LSF job scheduler\n",
    "    \n",
    "    job_id = Get_job_id(['bjobs', '-u', USER])\n",
    "    jobs = [job_id]\n",
    "    wait_on_lsf()\n",
    "    \n",
    "elif job_type==\"SLURM\" or job_type==\"Slurm\" or job_type==\"slurm\":\n",
    "    USER = os.getlogin()\n",
    "    \n",
    "#     partition = 'skx-normal' # Can be changed to another other partition used on TACC's Stampede2\n",
    "    \n",
    "    create_job_script_slurm(Child, num_nodes, max_time, omp_threads)  # Creates Slurm job submission script\n",
    "    os.system(f'sbatch job_{Child}.sh')   # Submits job script to the Slurm job Scheduler\n",
    "    \n",
    "    job_id - Get_job_id(['squeue', '-u', USER])\n",
    "    jobs = [job_id]\n",
    "    wait_on_slurm()\n",
    "    \n",
    "else: \n",
    "    os.environ['OMP_NUM_THREADS'] = f'{omp_threads}'                  # Sets OpenMP Threads to 4\n",
    "    os.system(f\"mpiexec -n {number_of_process} {fds_bin} {filename}\") # Runs FDS using 'mpiexec' command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Checkpoint Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Parses plot3d files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_region = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Run_Region = True\n",
    "\n",
    "UVW_Timer  =  UVW_Timer + DT_UVW_Timer      # Time\n",
    "\n",
    "while(Run_Region):\n",
    "    # Corrects .smv in order to work with fds2ascii\n",
    "    remove_leading_space(f'{Child}.smv') \n",
    "\n",
    "    # Reads HRR data in plot3d files\n",
    "    os.chdir(PATH)\n",
    "    Number_of_meshes = Nmx*Nmy*Nmz\n",
    "    reading_hrr(Child, Number_of_meshes)\n",
    "\n",
    "    ## 2.2 Extracts & converts HRR data to CSV files\n",
    "\n",
    "    # Reset current location back to starting location\n",
    "    os.chdir(PATH)\n",
    "\n",
    "    # Converts the CSV Files into Dataframes to be used to extract Heat Release Rate Values\n",
    "    Hrr = pd.DataFrame()\n",
    "    for i in range(1,Number_of_meshes+1):\n",
    "        temp = pd.read_csv(f\"{FDS_FOLDER}/{Child}_{i}.csv\")\n",
    "        temp = temp.drop(temp.index[0])\n",
    "        temp = temp.reset_index(drop=True)\n",
    "        Hrr  = Hrr.append(temp)\n",
    "        Hrr = Hrr.reset_index(drop=True)\n",
    "    Hrr = Hrr[[Hrr.columns[0],Hrr.columns[1],Hrr.columns[2],Hrr.columns[7],Hrr.columns[4]]]\n",
    "    Hrr.columns = ['x','y','z','hrr','T']\n",
    "    file1 = open(f'FDSFiles/chimney/{Child}_hrr.csv', 'r') \n",
    "    Lines = file1.readlines() \n",
    "    Ultima_linea = Lines[-1].split(\",\",3)\n",
    "    hrr_value = float(Ultima_linea[1])\n",
    "    if(float(Ultima_linea[1])==0.0):\n",
    "        break\n",
    "    rad_frac  = -float(Ultima_linea[2])/float(Ultima_linea[1]) \n",
    "\n",
    "    # Cleans the data and sets the data type\n",
    "    Hrr[\"hrr\"] = pd.to_numeric(Hrr[\"hrr\"], downcast=\"float\")\n",
    "    Hrr[\"x\"] = pd.to_numeric(Hrr[\"x\"], downcast=\"float\")\n",
    "    Hrr[\"y\"] = pd.to_numeric(Hrr[\"y\"], downcast=\"float\")\n",
    "    Hrr[\"z\"] = pd.to_numeric(Hrr[\"z\"], downcast=\"float\")\n",
    "    Mst[\"x\"] = pd.to_numeric(Mst[\"x\"], downcast=\"float\")\n",
    "    Mst[\"y\"] = pd.to_numeric(Mst[\"y\"], downcast=\"float\")\n",
    "    Mst.shape\n",
    "    # Filters HRR values greater than the specified threshold\n",
    "    Hrr = Hrr[Hrr['hrr'] >= hrr_threshold]\n",
    "    #Hrr = Hrr[Hrr['hrr'] != 0]\n",
    "    minimo_x = Hrr['x'].min()\n",
    "    maximo_x = Hrr['x'].max()\n",
    "  \n",
    "    minimo_y = Hrr['y'].min()\n",
    "    maximo_y = Hrr['y'].max()\n",
    "    print(f'Lower bound of x: {minimo_x}')\n",
    "    print(f'Upper bound of x:{maximo_x}')\n",
    "    print(f'Lower bound of y:{minimo_y}')\n",
    "    print(f'Upper bound of y:{maximo_y}')\n",
    "    # Defining the center of the location of the fire\n",
    "    #indice_maximo = Hrr['hrr'].idxmax()\n",
    "    #center_x =  math.floor(Hrr['x'].loc[indice_maximo])\n",
    "    #center_y =  math.floor(Hrr[\"y\"].loc[indice_maximo])\n",
    "    if (math.isnan(minimo_x) or math.isnan(maximo_x) or math.isnan(minimo_y) or math.isnan(maximo_y)):\n",
    "        break\n",
    "    center_x = math.floor((minimo_x+maximo_x)/2)\n",
    "    center_y = math.floor((minimo_y+maximo_y)/2)\n",
    "    \n",
    "    center_x = center_x - (center_x%Ro)\n",
    "    center_y = center_y - (center_y%Ro)\n",
    "    \n",
    "    if ((center_x < West)  or (center_x > East) or (center_y < South) or (center_y > North)):\n",
    "        break\n",
    "\n",
    "    # Update Region Number to next one, if needed\n",
    "    num_region = num_region + 1\n",
    "\n",
    "    # Coordinates of the new region's border\n",
    "    #Min_x = max(center_x - fire_radius, West)\n",
    "    #Max_x = min(center_x + fire_radius, East)\n",
    "    #Min_y = max(center_y - fire_radius, South)\n",
    "    #Max_y = min(center_y + fire_radius, North) \n",
    "    Min_x = int(input('Input lower bound of x: '))\n",
    "    Max_x = int(input('Input upper bound of x: '))\n",
    "    Min_y = int(input('Input lower bound of y: '))\n",
    "    Max_y = int(input('Input upper bound of y: '))\n",
    "    DTT = float(input('Input time to simulate in the Next Region: '))\n",
    "    rampa_time = float(input('Input the Rampa time in the Next Region: '))\n",
    "    \n",
    "    Run_Region = False\n",
    "    Mst   = Mst_original.copy()\n",
    "    Mst = Mst[(Mst.x > Min_x-Ro-1) & (Mst.x < Max_x+Ro+1) & (Mst.y > Min_y-Ro-1) & (Mst.y < Max_y+Ro+1)]\n",
    "    Mst = Mst[(Mst.x%Ro==0) & (Mst.y%Ro==0)]\n",
    "    Mst['Elevation'] = Mst['Elevation']-Mst['Elevation']%Ro\n",
    "    # Range of elevation\n",
    "    # Defines range of elevation\n",
    "    Min_z = math.floor(Mst['Elevation'].min())\n",
    "    Min_z = Min_z-(Min_z%(2*R))\n",
    "    Max_z = math.ceil(Mst['Elevation'].max())\n",
    "    Max_z = Max_z + (2*R-Max_z%(2*R))\n",
    "    \n",
    "    Medio_z =  (Min_z + Max_z)/2\n",
    "    Min_z   = Medio_z-fire_radius\n",
    "    Max_z   = Medio_z+fire_radius\n",
    "\n",
    "    Regiones.append([Min_x,Max_x,Min_y,Max_y,Min_z,Max_z])\n",
    "    if(Hrr['hrr'].sum()==0):\n",
    "        break\n",
    "    # Delete the cell if it is under the obstacles\n",
    "    Hrr = delete_under(Hrr)\n",
    "    \n",
    "    # Determining the 'volumen' of the cells\n",
    "    \n",
    "    #Hrr['hrr'] = (hrr_value/(Rx*Ry*Rz*Hrr['hrr'].sum()))*Hrr['hrr']\n",
    "    Hrr['hrr'] = (hrr_value/(Hrr['hrr'].sum()))*Hrr['hrr']\n",
    "    \n",
    "    if (Hrr.shape[0] < 1):\n",
    "        break\n",
    "    # Repeat Steps 1.2 - 3 (Loop)\n",
    "\n",
    "    # Defines input variables for the next region (with respect to the previous FDS run)\n",
    "    T_begin = T_end\n",
    "    T_end   = T_begin+DTT\n",
    "    Child   = f\"Region{num_region}\"\n",
    "    foldername = f'chimney'\n",
    "    filename   = f'{Child}.fds'\n",
    "    Hrr.to_csv(f'{PATH}/FDSFiles/{foldername}/Hrr_{Child}.csv', index=False)\n",
    "    # Recreates input FDS file for the next region of interest\n",
    "    restart_fds_file(T_begin, T_end, DT, PC, Nmx, Nmy, Nmz, Hrr, Child)\n",
    "\n",
    "    # Change current location to the input FDS file location\n",
    "    os.chdir(f\"{PATH}/{FDS_FOLDER}\") \n",
    "\n",
    "    # Clear the list of jobids\n",
    "    if 'jobs' in locals():\n",
    "        jobs.clear()\n",
    "\n",
    "    # Options: LSF, Slurm, or direct command (mpiexec)\n",
    "    if job_type==\"LSF\" or job_type==\"Lsf\" or job_type=='lsf':\n",
    "        create_job_script_lsf(Child, num_nodes, max_time, omp_threads)    # Creates LSF job submission script\n",
    "        os.system(f'bsub < job_{Child}.bsub') # Submits job script to the LSF job scheduler\n",
    "\n",
    "        job_id = Get_job_id(['bjobs', '-u', USER])\n",
    "        #job_id = input(\"Enter Job ID just started: \") # Gets the job id & waits for it to finish to run the rest of the notebook\n",
    "        jobs = [job_id]\n",
    "        wait_on_lsf()\n",
    "    elif job_type==\"SLURM\" or job_type==\"Slurm\" or job_type==\"slurm\":\n",
    "        create_job_script_slurm(Child, num_nodes, max_time, omp_threads)  # Creates Slurm job submission script\n",
    "        os.system(f'sbatch job_{Child}.sh')   # Submits job script to the Slurm job Scheduler\n",
    "\n",
    "        job_id = input(\"Enter Job ID just started: \") # Gets the job id & waits for it to finish to run the rest of the notebook\n",
    "        jobs = [job_id]\n",
    "        wait_on_slurm()\n",
    "    else: \n",
    "        os.environ['OMP_NUM_THREADS'] = f'{omp_threads}'                  # Sets OpenMP Threads to 4\n",
    "        os.system(f\"mpiexec -n {number_of_process} {fds_bin} {filename}\") # Runs FDS using 'mpiexec' command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regiones = pd.DataFrame(Regiones)\n",
    "Regiones.columns=['Min_x','Max_x','Min_y','Max_y','Min_z','Max_z']\n",
    "Regiones.to_csv(f'{PATH}/FDSFiles/{foldername}/Regiones.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(Run_Region):\n",
    "    if not path.exists(f\"{PATH}/Regiones\"):\n",
    "        os.system(f\"mkdir Regiones\")\n",
    "    os.system(f\"cp {PATH}/FDSFiles/{foldername}/Region*_hrr.csv Regiones\")\n",
    "else:\n",
    "    os.chdir(f\"{PATH}\")\n",
    "    if not path.exists(f\"{PATH}/Median\"):\n",
    "        os.system(f\"mkdir Median\")\n",
    "    os.system(f\"cp {PATH}/FDSFiles/{foldername}/Region*_hrr.csv {PATH}/Median/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the HRR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region1hrr=pd.read_csv('Regiones/Region1_hrr.csv',skiprows=1)\n",
    "Region2hrr=pd.read_csv('Regiones/Region2_hrr.csv',skiprows=1)\n",
    "Region3hrr=pd.read_csv('Regiones/Region3_hrr.csv',skiprows=1)\n",
    "RegionMhrr=pd.read_csv('Median/Region1_hrr.csv',skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.gca()\n",
    "plt.plot(RegionMhrr[\"Time\"], RegionMhrr[\"HRR\"],color='#003333',label='Region1.2',linewidth=2)\n",
    "plt.plot(Region1hrr[\"Time\"], Region1hrr[\"HRR\"],color='#cc6600',label='Region1.2.1',linewidth=2)\n",
    "plt.plot(Region2hrr[\"Time\"], Region2hrr[\"HRR\"],color='#0000FF',label='Region1.2.2',linewidth=2)\n",
    "plt.plot(Region3hrr[\"Time\"], Region3hrr[\"HRR\"],color='#cc0066',label='Region1.2.3',linewidth=2)\n",
    "plt.xlabel('Time ($t$)',fontsize = 'medium')\n",
    "plt.ylabel('Heat Release Rate',fontsize = 'medium')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.savefig(f'Figures/Simulated_Region1.2_3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.gca()\n",
    "plt.plot(Region1hrr[\"Time\"], Region1hrr[\"HRR\"],color='#cc6600',label='Region1.2.1',linewidth=2)\n",
    "plt.plot(Region2hrr[\"Time\"], Region2hrr[\"HRR\"],color='#0000FF',label='Region1.2.2',linewidth=2)\n",
    "plt.plot(Region3hrr[\"Time\"], Region3hrr[\"HRR\"],color='#cc0066',label='Region1.2.3',linewidth=2)\n",
    "plt.xlabel('Time ($t$)',fontsize = 'medium')\n",
    "plt.ylabel('Heat Release Rate',fontsize = 'medium')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.savefig(f'Figures/three_regions_cubed_3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
